\Section{preliminaries}{Preliminaries}

Our pruning technique works on Datalog, a general language which can be used to
express static analyses declaratively \cite{Whaley2007,bravenboer}.  Normally,
these analyses and their underlying abstractions are encoded by one monolithic Datalog program
which evaluates a query abstractly.
For us, it will be convenient to consider the
Datalog program, which evaluates a query concretely,\footnote{We refer to this computation as ``concrete''
to contrast with abstract computation we will consider later,
but note that this ``concrete'' computation
could already contain some level of abstraction.
For example, the Datalog program might correspond to $\infty$-object-sensitivity
without abstraction and $k$-object-sensitivity with abstraction.
} as distinct from the abstraction, which transforms the input to
the Datalog program, resulting in an abstract evaluation of the query.  This separation
allows us to make theoretical statements
comparing the behavior of the same Datalog program across different
abstractions.

We first define Datalog and the computation of a concrete query
(\refsec{datalog}).  Then, we focus on the abstraction (\refsec{abstractions}),
which interacts with the Datalog program by transforming the input tuples.
Throughout this section, we will use \reffig{graphExample} as a running example.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\begin{center} {\bf Graph Example} \end{center}
{\bf Input relations}:
\[
\begin{array}{ll}
\edge(g,i,j) & \defn{edge from node $i$ to node $j$ in graph $g$} \\
\head(c,i)   & \defn{first element of array $c$ is $i$} \\
\ext(i,c,c') & \defn{$i$ prepended to $c$ yields $c'$: $c' = [i]+c$} \\
\end{array}
\]
{\bf Rules}:
\[
\begin{array}{l}
\path(g,[\initNode]). \\
\path(g,c')\ \dlogUpdate\ \path(g,c),\ \head(c,i),\ \edge(g, i, j),\ \ext(j, c, c'). \\
\common(g_1,g_2,i)\ \dlogUpdate\ \path(g_1,c),\ \path(g_2,c),\ \head(c,i). \\
\end{array}
\]
{\bf Query tuple}: $\xo = \common(\Ga,\Gb,3)$. \\
\\
{\bf Constants}: $\sC = \{ \Ga, \Gb, 0, 1, 2, 3, \vec{0}, \vek{01}, \dots \}$.
\\
\\
%{\bf Abstraction}:
%$\alpha_k(c) = \{ c' : \text{$c$ and $c'$ have same length $k$ prefix}\}$
%\\
%\\
\includegraphics[scale=0.5]{figures/graphExample}
\caption{\label{fig:graphExample}
A simple example illustrating Datalog:
Suppose we have two graphs $\Ga$ and $\Gb$ defined on the same set of nodes $\{0,1,2,3\}$,
and we want to compute the query tuple $\common(\Ga,\Gb,3)$,
asking whether the two graphs have a common path from node $0$ to node $3$.
Given the input tuples encoding the graph,
the Datalog program computes a set of derived tuples from the rules.
In this case, the absence of $\common(\Ga,\Gb,3)$ from the derived tuples means the query is false (proven).
}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Subsection{datalog}{Datalog}

A {\em Datalog program} consists of
a set of {\em constants} $\sC$ (e.g., $\initNode,\vec{03} \in \sC$),
a set of {\em variables} $\sV$ (e.g., $i, j \in \sV$), and
a set of {\em relations} $\sR$ (e.g., $\edge \in \sR$).

A {\em term} $t$ consists of a relation $t.r \in \sR$ and a list of arguments $t.\ba$,
where each argument $t.a_i$ is either a variable or a constant,
(that is, $t.a_i \in \sV \cup \sC$) for $i = 1, \dots, |t.\ba|$.
We will write a term in any of the following three equivalent ways:
\begin{align}
t \quad\equiv\quad t.r(t.\ba) \quad\equiv\quad t.r(t.a_1, \dots, t.a_{|t.\ba|}).
\end{align}
For example, $\ext(j,c,c')$ is a term.
We call a term whose arguments are all constants a {\em tuple}
(e.g., $\ext(\initNode, [\,], \vec{\initNode})$).
Note that the tuple includes the relation as well as the arguments.
We let $\xo$ denote a designated {\em query tuple} (e.g., $\common(\Ga,\Gb,3)$),
whose truth value we want to determine.

Let $\sZ$ denote the set of rules,
where each {\em rule} $z \in \sZ$ consists of a target term $z.t$ and a set of source terms $z.\bs$.
We write a rule with $z.t = t$ and $z.\bs = \{ s_1, \dots, s_k \}$ as
\begin{align}
t \dlogUpdate s_1, \dots, s_k.
\end{align}

An {\em assignment} is a function $f : \sV \mapsto \sC$ which maps variables to
constants.  To simplify notation later, we extend an assignment $f$ so that it
can be applied (i) to constants ($f(c) = c$ for $c \in \sC$), and (ii) to terms by
replacing the variables in the term with constants ($f(t) = t.r(f(t.a_1), \dots, f(t.a_{|t.\ba|}))$).

\begin{figure}[t]
%{\bf Notation:} \\
\[
\begin{array}{ll}
\sC                           & \defn{concrete values} \\
\sP(\sC)                      & \defn{abstract values} \\
\alpha : \sC \mapsto \sP(\sC) & \defn{abstraction, maps to equivalence class} \\
\xo                           & \defn{designated query tuple} \\
\bD(X)                        & \defn{derivations of $\xo$ using input tuples $X$} \\
\bE(X)                        & \defn{tuples involved in deriving $\xo$} \\
\bP(X)                        & \defn{input tuples relevant to deriving $\xo$} \\
A_k                           & \defn{abstract input tuples after $k$ iterations} \\
\tilde A_k                    & \defn{relevant abstract input tuples after pruning} \\
\end{array}
\]
\caption{\label{fig:notation} Notation.}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\Subsection{derivations}{Derivations}
\paragraph{Derivations}

A Datalog program takes a set of input tuples and derives new
tuples.  To formalize this computation, we define the notation of a derivation.

A {\em derivation} (of the query $\xo$) with respect to a set of input tuples
$X$ is a sequence $\bx = (x_1, \dots, x_n)$ such that
\begin{enumerate}
\item [(i)] for each $i = 1, \dots, n$, we have $x_i \in X$; or
there exists a set of indices $J$ such that $(J,i)$ satisfies the following two conditions:
$j < i$ for each $j \in J$, and
there is a rule $z \in \sZ$ and an assignment $f$
such that $f(z.t) = x_i$ and
$\{ x_j : j \in J \} = \{ f(s) : s \in z.\bs \}$;
\item [(ii)] $x_n = \xo$; and
\item [(iii)] 
for each $j = 1, \dots, n\!-\!1$,
there exists $J$ such that $j \in J$ and an index $i$
such that $(J,i)$ satisfies the two conditions in (i).
\end{enumerate}
Define $\bD(X)$ to be the set of all derivations with respect to the input tuples $X$.

% Explain
Condition (i) says that each tuple in a derivation
should either be given as an input tuple ($x_i \in X$)
or be the result of some rule $z \in \sZ$.
Condition (ii) says that the query tuple $\xo$ is derived at the end.
Condition (iii) says that in the derivation of $\xo$, every tuple is somehow ``relevant'' for deriving $\xo$.
%As we will see later, this condition is important because it allow us to
%define the set of irrelevant tuples that can be pruned.

%A Datalog program computes $\bD(X)$.
We say that the query $\xo$ is false (proven) if and only if $\bD(X)$ is empty.
Although this answer to the query is the ultimate quantity of interest,
the Datalog program can be used to provide more information, which will be useful for pruning.
Specifically, we define $\bE(X)$ as the set of all tuples used in any derivation (of $\xo$)
and $\bP(X)$ to be the subset of $\bE(X)$ which are input tuples:
\begin{align}
\label{eqn:Pdef}
\bE(X) &\eqdef \bigcup_{\bx \in \bD(X)} \bx, \\
\bP(X) &\eqdef X \cap \bE(X).
%\bP(X) \eqdef \{ x \in X : x \in \bx \in \bD(X) \}.
\end{align}
We call $\bP(X)$ the set of {\em relevant input tuples}.  As we will see later,
any tuple not in this set can be safely pruned.
In fact, $\bP(X)$ also tells us whether the query is true or false.
In particular, $\bD(X) = \emptyset$ if and only if $\bP(X) = \emptyset$ (assuming $\xo$ cannot be derived trivially without inputs).
This equivalence suggests that proving and pruning are intimately related;
in some sense, proving the query is just pruning away the query tuple.
In the remainder of the paper, we will make heavy use of $\bP$ as the principal
proving/pruning operator.
In our graph example, $\bD(X) = \bP(X) = \emptyset$,
but as we will see later, this is not true if we apply an abstraction to $X$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Computation}

Given input tuples $X$, a Datalog solver returns the set of derived tuples $Y$;
the query is proven if $\xo \not\in Y$.  Note that $Y$ is a superset of the
relevant derived tuples $\bE(X)$,
which itself is a superset of the relevant input tuples
$\bP(X)$, which is needed for pruning.

We can compute $\bP(X)$ by using the Datalog program transformation technique described in 
\cite{liang11minimal}:
We augment our existing Datalog program with a set of new relations $\sR' = \{ r' : r \in \sR \}$.
For a term $t = t.r(t.\ba)$ we let $t' = t.r'(t.\ba)$ be the term that uses the corresponding new relation $t.r'$.
We then add the following new Datalog rules:
\begin{align}
\xo' &\dlogUpdate \xo, \label{eqn:revBase} \\
s'   &\dlogUpdate z.t', z.\bs \quad \text{for each $z \in \sZ$ and $s \in z.\bs$.} \label{eqn:indBase}
\end{align}
For example, the last rule of the original Datalog program in \reffig{graphExample} generates the following three new rules:
\begin{center}
\scalebox{0.85}{
$
\begin{array}{lcl}
\path'(g_1,c)    &\!\!\dlogUpdate\!\!& \common'(g_1,g_2,i),\ \path(g_1,c),\ \path(g_2,c),\ \head(c,i). \\
\path'(g_2,c)    &\!\!\dlogUpdate\!\!& \common'(g_1,g_2,i),\ \path(g_1,c),\ \path(g_2,c),\ \head(c,i). \\
\head'(c,i)      &\!\!\dlogUpdate\!\!& \common'(g_1,g_2,i),\ \path(g_1,c),\ \path(g_2,c),\ \head(c,i). \\
\end{array}
$
}
\end{center}

The key is that a tuple $x'$ is derived by the new Datalog program if and only if $x \in \bE(X)$.
Rules generated by \refeqns{revBase}{indBase} construct $\bE(X)$ recursively:
The base case \refeqn{revBase} states that the query tuple $\xo \in \bE(X)$.
The recursive case \refeqn{indBase} states that if $x \in \bE(X)$ and a rule $z$ (with some assignment $f$)
was used to produce $x$, then for every source term $s \in z.\bs$ of that rule,
we also have $f(s) \in \bE(X)$.
Having obtained $\bE(X)$, we get $\bP(X)$ by keeping only tuples in $X$.

The advantage of this technique is that we can use any Datalog solver as a black-box to compute $\bP(X)$.
%Therefore, running the new Datalog program and examining tuples of the form $x'$ yields $\bP(X)$.
In practice, we will not actually run $\bP$ on concrete input tuples $X$, but on abstract input tuples.
From the point of view of the Datalog solver, there is no difference between the two.
We consider constructing abstract tuples next.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\Subsection{abstractions}{Abstractions}

Given a Datalog program, an {\em abstraction} is an equivalence relation over
constants $\sC$.  In particular, we represent the abstraction as the
function which maps each constant to its equivalence class.
\begin{definition}
\label{def:abstraction}
An abstraction is a function $\alpha : \sC \to \sP(\sC)$
such that for each set $s \in \range(\alpha)$,
we have $\alpha(c) = s$ for all $c \in s$.
\end{definition}
\noindent
We will refer to constants $\sC$ as the concrete values and $\range(\alpha)$ as
the abstract values.
We assume the natural partial order on abstractions,
where $\alpha_1 \preceq \alpha_2$ if and only if $\alpha_1(c) \supseteq \alpha_2(c)$ for all $c$---that is, $\alpha_2$ is finer than $\alpha_1$.

%\Subsection{klimitedAbstraction}{$k$-limited abstraction}
\paragraph{Example: $k$-limited abstraction}

The main abstraction we will work with in this paper is the $k$-limited abstraction \cite{kcfa,kobj}.
Our general theory does not depend on this particular choice, but we present
the abstraction here so we can use it as a running example.

First, we define some notation.
Let $\dom$ be an arbitrary set;
for the graph example of \reffig{graphExample}, let $\dom = \{ 0, 1, 2, 3 \}$ be the nodes of the graph;
later, $\dom$ will be the set of allocation sites in a program.
Define a {\em chain} $c \in \dom^*$ to be a finite sequence of elements from this set.
Let $|c|$ denote the length of the chain.
Let $c[i]$ be the $i$-th element of $c$ (starting with index 1) and
let $c[i..j]$ be the subchain $[c[i] \cdots c[j]]$
(boundary cases: $c[i..j] = [\,]$ if $i > j$ and $c[i..j] = c[i..|c|]$ if $j > |c|$).
For two chains $c_1$ and $c_2$, let $c_1+c_2$ denote their concatenation.

The {\em $k$-limited abstraction}
partitions chains based on their length $k$ prefix.
First, for a chain $c$, let $c*$ denote the set of all chains
with prefix $c$; formally:
\begin{align}
c* \eqdef \{ c' \in \H^* : c'[1..|c|] = c \}.
\end{align}
For an integer truncation level $k \ge 0$, define the $k$-limited abstraction $\klimabs_k$ as follows:
\begin{align}
\label{eqn:klimitedAbstraction}
\klimabs_k(c) \eqdef
\begin{cases}
\{c\}     & \text{if $|c| < k$} \\
c[1..k]*  & \text{if $|c| \ge k$}. \\
\end{cases}
\end{align}
If the concrete chain $c$ is shorter than length $k$,
we map it to the singleton set $\{ c \}$;
otherwise, we map it to the set of chains that share the first $k$ elements.
It is easy to verify that $\klimabs_k$ is a valid abstraction under \refdef{abstraction}.

For example, if $c = \vec{01}$,
then we have that $\klimabs_1(c) = [0]* = \{ [0], [00], [01], [000], \dots \}$
are the chains that start with $[0]$.
As another example, \reffig{repeatingExample} shows the range of $\klimabs_3$.

\begin{figure}
\[
\arraycolsep=3.5pt
\begin{array}{llllllll}
\{\vec{0}\}    &            &              &            & \{\vec{1}\} \\
\{\vec{00}\}   &            & \{\vec{01}\} &            & \{\vec{10}\} &            & \{\vec{11}\} \\
\vec{000}*     & \vec{001}* & \vec{010}*   & \vec{011}* & \vec{100}*   & \vec{101}* & \vec{110}* & \vec{111}*
\end{array}
\]
\caption{\label{fig:repeatingExample}
The 14 abstract values defined by the $k$-limited abstraction $\klimabs_k$
with $\dom = \{ 0, 1 \}$ and $k = 3$.
Specifically, $\klimabs_k$ maps each chain $c \in \dom^*$ to one of the values above.
}
\end{figure}

It is important that we represent $\{c\}$ and $c*$ as distinct abstract values.
In contrast, traditional $k$-limited analyses are parametrized by a set $S$ of abstract values ``$c$'',
where each abstract ``$c$'' represents the set of concrete chains whose longest
matching prefix in $S$ is $c$.
With this setup,
every concrete chain would map to some abstract value regardless of $S$
(note that we must have $\text{``$[\,]$''} \in S$).
Therefore, pruning would be impossible using this representation.

%Suppose that $k=3$.
%Na\"ively, ``$\vec{01}$'' would just represent $\{\vec{01}\}$.
%The problem comes when we prune.
%If we prune ``$\vec{010}$'', then ``$\vec{01}$'' really represents $\{\vec{01}\}\cup \vec{010}*$
%because any chain starting with $\vec{010}$ must now fall back on ``$\vec{01}$''.
%This is unacceptable because pruning tuples should not change the abstraction.
%Actually, the situation is worse, because (i) in fact no pruning
%(in the sense that some chains are ignored)
%would happen and (ii) the resulting analysis would be much more imprecise because
%``$[\,]$'' is always present for representing the context of the main method,
%but this is a prefix of any chain.

% Example
%In the context of our example (\reffig{graphExample}),
%we could define an abstraction
%that maps a sequence $c$ to the set of sequences that have the same first element as $c$
%(e.g., $\alpha([10]) = \{ [1], [10], [11], \dots \}$).
%This abstraction is a simplified version of the abstractions we use in our
%$k$-limited analyses (see \refsec{abstractionExamples}).

\paragraph{Extending the abstraction}

Given an abstraction $\alpha$, it will be useful to extend the definition of
$\alpha$ to not just concrete values, but also to abstract values,
and (sets of) concrete/abstract tuples.

% Extend to sets
First, we extend $\alpha$ from concrete values $c$ to abstract values $s$ as follows:
\begin{align}
\alpha(s) \eqdef \{ \alpha(c) : c \in s \}, \quad s \in \sP(\sC).
\end{align}
Note that $\alpha(s)$ returns a set of abstract values.
This allows us to naturally define the composition of two abstractions.
In particular, given two abstractions, $\alpha$ and $\beta$,
define their composition to be:
\begin{align}
(\alpha \circ \beta)(c) \eqdef \cup_{s \in \alpha(\beta(c))} s.
\end{align}
Note that the composition $\alpha \circ \beta$ need not be an abstraction
even if $\alpha$ and $\beta$ are.\footnote{For example,
suppose $\sC = \{1,2,3\}$;
$\alpha(1) = \alpha(2) = \{1,2\}$, $\alpha(3) = \{ 3 \}$; and
$\beta(1) = \beta(3) = \{1,3\}$, $\beta(2) = \{ 2 \}$.
Then $(\alpha \circ \beta)(1) = \{1,2,3\}$ but $(\alpha \circ \beta)(2) = \{1,2\}$.
Therefore, $\alpha \circ \beta$ is not a valid abstraction.
}
Therefore, when we compose abstractions in \refsec{algorithm},
it will be important to check that the resulting compositions are valid abstractions.

An important case in which compositions yield valid abstractions
is when $\alpha \preceq \beta$ ($\beta$ is finer than $\alpha$).
In this case, $\alpha \circ \beta = \alpha$,
corresponding to the fact that
applying a finer abstraction first has no impact.

% Extend to tuples
Next, we extend $\alpha$ to concrete tuples $x$ and sets of concrete tuples $X$
in the natural way:
\begin{align}
\alpha(x) &\eqdef x.r(\alpha(x.a_1), \dots, \alpha(x.a_{|x.\ba|})), \\
\alpha(X) &\eqdef \{ \alpha(x) : x \in X \}.
\end{align}
Here, $\alpha(x)$ is an {\em abstract tuple} (one where the arguments are abstract values)
and $\alpha(X)$ is a set of abstract tuples.
For example:
\begin{align}
\pi_1(\ext(1, [0], [10])) = \ext(1, [0]*, [1]*). \nonumber
\end{align}
Finally, we extend $\alpha$ to abstract tuples $b$ and sets of abstract tuples $B$:
\begin{align}
\alpha(b) &\eqdef \{ b.r(s_1, \dots, s_{|b.\ba|}) : \forall i, s_i \in \alpha(b.a_i) \}, \label{eqn:alphab} \\
\alpha(B) &\eqdef \cup_{b \in B} \alpha(b). \label{eqn:alphaB}
\end{align}
\refeqn{alphab} applies the abstraction function to each component of $b$ and takes the cross product over the resulting abstract values;
the result is a set of abstract tuples.
\refeqn{alphaB} aggregates these sets of abstract tuples.
For example:
\begin{align}
\pi_1(\ext(1, [00]*, [10]*)) = \{ \ext(1, [0]*, [1]*) \}. \nonumber
\end{align}

\paragraph{Using the abstraction}

Given an abstraction $\alpha$,
we want to run the Datalog program to compute an abstract answer to the query.
We do this by applying the abstraction to the concrete input tuples $X$,
producing a set of abstract input tuples $\alpha(X)$.
We then feed these tuples into the Datalog program to produce $\bP(\alpha(X))$.
(Note that the Datalog program is oblivious to whether the tuples are abstract or concrete.)
\reffig{graphDerivation} shows an example of performing this computation on the
graph example from \reffig{graphExample} with the $k$-limited abstraction $\pi_1$.

We say the query is proven by $\alpha$ if $\bP(\alpha(X)) = \emptyset$.
Because abstraction is sound,
this happens only if the query is actually false ($\bP(X) = \emptyset$).
This fact is stated formally below (see \refapp{proofs} for the proof):
\begin{proposition}[Abstraction is sound]
\label{prop:soundness}
Let $\alpha$ be an abstraction and let $X$ be any set of input tuples.
If $\bP(\alpha(X)) = \emptyset$ (the query is false abstractly),
then $\bP(X) = \emptyset$ (the query is false concretely).
\end{proposition}

\FigStar{figures/graphDerivation}{0.3}{graphDerivation}{
Computation of $\bP(\pi_1(X))$ on the graph example from \reffig{graphExample},
where $X$ is the set of concrete input tuples, and $\pi_1$ is the $1$-limited abstraction
which maps each path onto the set of paths with the same first element.
%(e.g., $\alpha(\vec{10}) = \{\vec{1}, \vec{10}, \vec{11}, \dots \} \eqdef \vec{1}*$).
In the figure,
each abstract tuple is derived by a rule whose source terms are connected via incoming edges.
Relevant input tuples ($\bP(\pi_1(X))$, shown in green) are the ones which are reachable by following the edges backwards;
ones which are not backwards-reachable are pruned ($\pi_1(X)\backslash\bP(\pi_1(X))$, shown in red).
}

If $\alpha$ is coarse, $\bP(\alpha(X))$ will be imprecise;
but if $\alpha$ is fine, $\bP(\alpha(X))$ will be expensive to compute.
The next section shows how pruning can allow us to use a fine abstraction $\alpha$
without incurring the full cost of computing $\bP(\alpha(X))$.
