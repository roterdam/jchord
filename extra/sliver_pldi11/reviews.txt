===========================================================================
                          PLDI 2011 Review #331A
                 Updated Friday 31 Dec 2010 8:42:09am CST
---------------------------------------------------------------------------
          Paper #331: Scaling Abstraction Refinement via Pruning
---------------------------------------------------------------------------

                      Overall merit: 3. Weak accept
                 Reviewer expertise: 3. Knowledgeable

                         ===== Paper summary =====

Paper presents a technique to scale datalog query processing using pruning.  Paper defines an abstraction scheme where abstraction functions map constants into equivalence classes. The coarser the abstraction, the more tuples can be merged together and queries can be computed easily. An empty query is still a correct answer, but a noneqmpty quey could be because of precision loss due to merging. Paper presents a technique by which we can restrict the inputs that are needed to answer a query. In particular, suppose we have two abstractions \alpha and \beta, and \beta is coarser than \alpha, then we can first compute a pruning with respect to the coarser abstraction \beta, and use this pruning to restrict the inputs while processing the query with respect to the finer abstraction \alpha.

            ===== Area of the paper (List all that apply) =====

2, 20

              ===== Evaluation and comments for author =====

I really like the clarity and simplicity of the theoretical parts of the paper. The presentation is lucid. Theorem 1 is very well presented with very clear intuitions of why it holds. Concepts such as abstraction and pruning in Datalog are very well explained.  The main criticism I have about the paper is that the empirical results are weak and are not well presented. Since paper uses bddbddb, the number of input tuples doesn’t directly lead to performance gains since BDD sizes are not directly dependent on the number of tuples represented by the BDD. Paper acknowledges this, but Figures 10, 11 and 12 present input tuple sizes in great detail. Table 4 presents some interesting data about how many queries can be answered using the techniques introduced in the paper, but it is not clear what the columns 1-5 even represent! (I guess they may be the abstractions in Table 2?)

Minor presentational comments:
Page 2. The predicate ext(i,c,c’) has arguments c and c’ which are unbounded lists. This is not datalog, and not decidable!  Datalog usually refers to fragments that are deciable in cubic time, and do not allow structures like lists are trees as arguments of predicates.

Page 5, Figure 6: It might be useful to point out where the “chains” are in the datalog program and relate the program to the abstratctions presented in Section 5.

===========================================================================
                          PLDI 2011 Review #331B
                 Updated Thursday 6 Jan 2011 8:40:16am CST
---------------------------------------------------------------------------
          Paper #331: Scaling Abstraction Refinement via Pruning
---------------------------------------------------------------------------

                      Overall merit: 2. Weak reject
                 Reviewer expertise: 4. Expert

                         ===== Paper summary =====

The paper proposes a technique for scaling static analyses by pruning the set of inputs. The idea is that of working on static analyses that can be expressed as Datalog programs. A Datalog program takes a set of input tuples and derives new tuples via a set of inference rules; the answer to a client query corresponds to whether a give tuple can be derived.

            ===== Area of the paper (List all that apply) =====

2 3

              ===== Evaluation and comments for author =====

The work corresponds on the description of an algorithm that iterates
two steps of computation: The first step consists in reducing
(pruning) the set of input tuples from which generating the
derivation, the second is a refinement process obtained by applying a
further more concrete abstraction.  I believe that the idea is very
interesting but I found several main problems in the paper.

Presentation: The intuitive part of the paper is very well written,
from the introduction the reader has a clear idea of the problem and
of what the author(s) aim to obtain. The problem is that this clarity
is lost along the paper. In particular, the general theory is ok, even
if the running example could be better exploited. But Sections 4 and 5
are quite hard to follow. In Sect. 4 the explanation are not
sufficient for allowing the reader to perfectly connect the theory,
and the algorithm, with what happens here. Sect. 5 does not explain
the intuitive meaning of the four abstractions (note that only three
abstractions are cited in the beginning of the section). For instance
for the k-limited abstraction, the reader takes some time for
understanding how it works and then it discovers in the end that it
seems that this abstraction is not good for pruning. The problem is
that the author(s) never say this explicitly and does not explain why
it is important to introduce anyway the abstraction. Another question
arising in this section is: why these abstractions are useful? what drives the
choice of these abstractions for the prune and for the pre-prune?
I think that to answer these questions it is important to make the theory
really general and usable. Finally Section 6 is very important to
understand the real impact of this work, but it is quite hard to
decipher.

Completeness: There are two points in the paper where the author(s)
states that the pruning process is complete. The problem is that this
assertion is never really explained and justified in the paper. First
of all the intuitive justification in the introduction is quite
odd. But then, at the end of page 3 one can read that Th.2 states both
soundness and completeness. The problem is that Th. 2 cites only
correctness (as also the name of the theorem states). Hence,
completeness is never really mentioned. The things are made even
worser by the example. In fact, in Fig. 1 we can note that the query
common(G1,G2,3) is false, since it cannot be derived. Indeed, as we
can observe, there isn't a common path form 0 to 3 in the two
graphs. But, Fig. 3 (badly explained), if I understand well, shows
that from the abstract inputs the query can be derived.  From what I
see and I read, soundness says that if a query is false in the abstract
then it is false in the concrete (proven in Th2), conversely
completeness says that if a query is not false in the abstract then it
is not false in the concrete, and I don't see where this is proved
while Fig.3 seems to show exactly the opposite.

Algorithm: The problem is exactly the generalization of what I wrote
about Sect. 5. Is there any requirement on the chosen abstractions? Is
there any relation between the \alpha_i and the \beta_i? I mean, even
if the algorithm works with general abstractions, I think that to make
the analysis useful the choice cannot be "random". 

Concluding, I think that the paper proposes a very interesting idea,
but would need a deep improvement in the presentation of the idea, of the
theory, of the algorithm, of the application, and of the experiments.

===========================================================================
                          PLDI 2011 Review #331C
                Updated Saturday 15 Jan 2011 6:12:30am CST
---------------------------------------------------------------------------
          Paper #331: Scaling Abstraction Refinement via Pruning
---------------------------------------------------------------------------

                      Overall merit: 4. Accept
                 Reviewer expertise: 3. Knowledgeable

                         ===== Paper summary =====

This paper presents a practical improvement of datalog-based program analysis.
The improvement records the tuples used during datalog evaluation and reduces them by doing an extra iteration with a coarser abstraction.
Soundness is given using an elegant theorem for monotonic functions.
The application performs k-object sensitivity analysis and shows that the proposed technique is essential in increasing the precision parameter.

            ===== Area of the paper (List all that apply) =====

2

              ===== Evaluation and comments for author =====

I like the elegant formulation of the analysis framework, including the key theorem (13).

One can view these results as a form of precision-preserving convergence of the acceleration. Such results are difficult to obtain, and the face that the authors have identified a case where they are useful is impressive.

Furthermore, the results, if measured through the scalability in the function of k, are impressive.
On the other hand, it is not clear that flow-insensitive and otherwise program-logic-ignorant analysis is meaningful for large k values.
In retrospect, is perhaps not surprising that you get the results of Table 4. 

It would be great if the authors could describe some more complex analysis in this framework, to capture more of program semantics.

At the very least, the authors could make some basic analysis (perhaps on parts of the benchmarks) and explain what the true sources of the imprecision in the resulting
unproven queries are, since it is certainly not the value of k.

Remark: the way I would prove (13) is entirely algebraic:
  right included in left: by monotonicy of P
  left included in right: we will use idempotence of P. 
    It thus suffices to show 
        P(alpha(X)) subseteq alpha(X),  (follows from P(Y) subseteq Y)
        P(alpha(X)) subseteq alpha(P(beta(X)))  (follows from beta being coarser, P monotonic, and alpha mapping into equivalence class)

In introduction, the statement that system approximation is not overapproximation sounds a little misleading. Isn't it simply the fact that one approximates client together with the system, so one obtains a smaller set of reachable states than the system under all possible clients?

===========================================================================
                          PLDI 2011 Review #331D
                  Updated Sunday 9 Jan 2011 3:51:08pm CST
---------------------------------------------------------------------------
          Paper #331: Scaling Abstraction Refinement via Pruning
---------------------------------------------------------------------------

                      Overall merit: 3. Weak accept
                 Reviewer expertise: 3. Knowledgeable

                         ===== Paper summary =====

This paper presents an abstraction refinement technique for a Datalog-based pointer analysis, which employs increasingly refined abstractions to prove Datalog queries. Coarser abstractions are used earlier and if a query cannot be proved, finer abstractions are used subsequently. This approach would allow the analysis to filter out irrelevant information and focus on the part of interest (i.e., relevant to the query), thereby improving scalability.

            ===== Area of the paper (List all that apply) =====

Static analysis

              ===== Evaluation and comments for author =====

The overall approach makes sense and could potentially be applied to a number of analyses. One major issue is that the proposed idea of pruning is very similar in spirit to the idea of introducing "match edges" in the CFL-reachability-based points-to analysis in Sridharan-Bodik PLDI'06 [19]. In this work, match edges that abstract paths of different lengths are exactly abstractions with different levels of granularity. A match edge is first used to obtain a relatively imprecise solution. If the solution is not sufficient for a client (i.e., query), it is further refined by removing this edge and considering subsequent match edges (that cross shorter paths). The process is repeated until the query can be proven or the budget runs out. Here the difference between the pruning refinement in this paper and a match edge in [19] is the program representation (i.e., Datalog v.s. CFL-reachability). However, there is a clear relationship between CFL-reachability and Datalog (Reps IST'98, Chaudhuri POPL'08): the CFL-reachability problem can be solved by translating the context-language-free grammar into Datalog chain queries (and vice versa). The authors should make a more substantial and detailed comparison between their work and the work in [19]. Another problem is that the approach overlaps significantly with the work in [10], and in some sense is incremental in the context of that work.

While the general theory presented in Section 3 is interesting, it has only one application (i.e., object-sensitivity) and the few abstractions discussed in Section 4 are not surprising. Discussing and implementing more applications of this theory would make the contributions stronger.

When does the PR algorithm terminate if a query cannot be proven? It seems that you need a "budget" (e.g., |A_t'|) in order to terminate the analysis. If this is the case, what budget was used?  In addition, you chose not to show the running times of the analyses because of "less predictable running times". But, if a budget is used, the comparison of analyses should be under the same budget. So here it is unclear what is the evaluation methodology. This issue should be clarified for the reader to fully understand the experiments.

