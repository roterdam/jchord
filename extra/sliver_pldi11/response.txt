We thank all reviewers for their useful comments; we will certainly
incorporate them into future versions of this paper.

REVIEWERS 1 and 4 ask about running time.  The relationship between the number
of input tuples (which we report as the main evaluation metric) and running
time is indeed obscured by using BDDs, but there is a definite correlation.  In
particular, pruning offers modest improvements in performance for small k
values, but the main win is that pruning allows us to even reach higher k
values at all (without pruning, the analysis just runs out of memory before
getting there).

REVIEWER 1: In Table 4, column k corresponds to using a k-limited abstraction.
We will improve the presentation of the results.

REVIEWER 4: The budget of the PR algorithm is determined by the number of
iterations.  In our experiments, we increased k until our analysis ran out
of memory (the horizontal axis of Figure 10 shows the k values which were
reached).

REVIEWER 4: to relate this paper with past work: Indeed, at a high-level, both
our paper and Sridharan-Bodik PLDI'06 refine an abstraction based on a client,
but there are some important differences: (i) their work is specific to pointer
analysis, whereas ours applies generally to any Datalog program; (ii) we also
provide rigorous theoretical guarantees on the precision of our pruning
approach.  As for Liang-Tripp-Naik POPL'11: (i) they focused on finding the
coarsest abstraction to prove a query by searching through the space of
abstractions---this was a scientific study, not a usable algorithm, whereas the
PR algorithm presented in this paper is very practical; (ii) we also are
effectively working with a much richer family of abstractions, where the
context-sensitivity can depend on the specific call chain rather than just the
allocation site.

REVIEWER 2:

To provide more motivation for the particular abstractions we used: First, we
worked with k-limited and class-based abstractions because these are standard
abstractions in pointer analysis which have traditionally faced scalability
issues.  On \alpha_i and \beta_i: usually \beta_i is \alpha_i composed with
another abstraction \tau.  One intuition is that \tau and \alpha_i should be
"complementary"; the effort spent pre-pruning using \tau should neither be
trivial nor redundant with \alpha_i.

Regarding how the correctness of Theorem 2 is related to soundness and
completeness: what we mean is any query we can prove directly using a fine
abstraction we can also prove with pruning (completeness) and vice-versa
(soundness).  When the fine abstraction is no abstraction (concrete), this is
the usual notion of soundness/completeness.

Figure 3 only shows computation of P(X) in the first iteration of the pruning
algorithm.  In this iteration, the red tuples pruned.  In the next iteration,
using a finer abstraction, common(G1,G2,3) will not be reachable, as desired.

REVIEWER 3:

Regarding the comment about system approximation and overapproximation: we do
not view pruning as system approximation but rather as program slicing: one
needs to be careful about what is pruned/sliced out to ensure soundness; for
example, if you prune away all the tuples, you can "prove" anything.
