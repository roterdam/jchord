\Section{introduction}{Introduction}

% Problem: want precision, abstractions don't scale up, even with
% client-driven, etc.
Making a static analysis more precise requires increasing the complexity of the
supporting abstraction---in pointer analysis, by increasing the amount of
context/object sensitivity \cite{kcfa, kobj, MilanovaRountevRyder2005,
WhaleyLam2004, LhotakHendren2006, LhotakHendren2008}; or in model checking, by
adding more abstraction predicates \cite{graf97predicate,slam}.
However, the complexity of these analyses often grows exponentially as the
abstraction is refined.
Much work has been done on curbing this exponential growth
(e.g., client-driven \cite{GuyerLin2003} and demand-driven
\cite{HeintzeTardieu2001} approaches in pointer analysis;
lazy abstraction \cite{henzinger02lazy,mcmillan06lazy} and other iterative refinement approaches in model checking).
We refer to these techniques as {\em selected refinement},
where the main idea is to only refine an abstraction along components
deemed relevant according to client feedback.

% Pruning setup
In this paper, we introduce {\em pruning}, a new approach which represents a
significant departure from existing selected refinement techniques.  Pruning is
applicable to static analyses represented by a set of inference rules where a
program property of interest (a client query) is proven by the inability to
derive a designated fact using the given rules.  For concreteness, assume that
the static analysis is expressed as a Datalog program.  A Datalog program takes
a set of input tuples and derives new tuples via a set of inference rules.
These inference rules capture the program semantics and computation of the
client query; the input tuples encode the program we are analyzing and the
abstraction we are using.  The program property is proven if the
designated query tuple cannot be derived.

% Pruning idea
The key idea behind pruning is to identify input tuples which are provably
irrelevant for deriving the query tuple and remove these tuples completely from
analysis.  Consequently, when the abstraction is refined, only the relevant
tuples are refined, resulting in potentially major computational savings.  It
is helpful to think of pruning in terms of program slicing, where
irrelevant parts of the program (irrelevant input tuples) are removed,
resulting in a smaller program that is cheaper to analyze.  Existing selected
refinement techniques attempt to keep the set of input tuples small by simply
not refining some of them; pruning keeps the set small by removing some of them
entirely.

% Soundness
Pruning can be a dangerous affair though.  With selected refinement,
we are always performing a static analysis with respect to an abstraction
and therefore inherit the soundness guarantees of abstract interpretation.
However, once we start pruning input tuples, we are no longer running a valid
static analysis of the original program.  Soundness therefore is no longer automatic,
though we do prove that our method is sound with respect to the given client.

% Completeness
While soundness is trivial for selected refinement but requires some
argument for pruning, the situation is reversed for {\em completeness}.  By
completeness, we mean that the analysis is as precise as
if we had refined all the components of an abstraction.  Selected
refinement only refines a subset of an abstraction, so it is unclear
that the resulting abstraction is as precise as an abstraction obtained by
refining all components.  However, with pruning, we conceptually work with the
fully-refined abstraction; and by removing input tuples, we cannot prove fewer
queries; thus, completeness is automatic.

% Refinement algorithm
To capitalize on the idea of pruning, we propose an algorithm, which we
call the {\em Prune-Refine algorithm}.  The idea is to start with a coarse abstraction
and prune the irrelevant input tuples before refining the abstraction; the
algorithm iterates until the query is proven or a specified computational budget
is reached.  We prove that the Prune-Refine algorithm computes the same answers to client queries
as directly using a refined abstraction without pruning, which would be precise
but possibly infeasible.

% Slivers
We apply pruning to the $k$-object-sensitivity abstraction
\cite{kobj}, where objects in the heap are abstracted into chains of
allocation sites; these chains are the input tuples we maintain.
Although the main contribution of this paper is the general
pruning technique, we also make the following contributions specific to
$k$-limited pointer analysis which arise due to pruning: First, we show
that we need a more careful treatment of the $k$-object-sensitivity abstraction.
Second, we introduce a new abstraction which limits
chains to length $k$ and truncates to avoid repeating
allocation sites; this is an effective way to increase $k$ without getting bogged down by long chains created by recursion.
Third, we show that an abstraction that
replaces allocation sites by types (a generalization of
\cite{smaragdakis11context}) is effective for pruning.

% Experiments
We ran our experiments on \numBenchmarks\ Java benchmarks using three clients that
depend heavily on having a precise pointer analysis: downcast safety
checking, monomorphic call site inference, and race detection.
We show that with pruning, our Prune-Refine algorithm enables us to perform $k$-object-sensitivity
analysis with a substantially much finer abstraction (larger $k$)
compared to a full $k$-object-sensitive analysis or even using the selected
refinement strategy of \cite{liang11minimal}.
In a few cases, the non-pruning approaches hit a wall around $k=3$ but the Prune-Refine
algorithm is able to go well beyond $k=10$.
